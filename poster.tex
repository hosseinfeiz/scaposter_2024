\documentclass[25pt, a0paper, landscape]{tikzposter}
\usepackage{etstikzposter}
\usepackage{tikz}
\usepackage{multirow} % Package for multirow tables
\usetikzlibrary{arrows, decorations.markings, arrows.meta, positioning} % TikZ libraries
\usepackage{overpic} % Overlay pictures
\usepackage{multicol} % Multiple columns
\usepackage[backend=biber]{biblatex} 
\addbibresource{main.bib} % Point to your .bib file
% Font settings
\usepackage[sfdefault]{FiraSans} % Use Fira Sans for sans-serif text
\usepackage{graphicx}
\usepackage{fontspec}
\usepackage{unicode-math} 
\usepackage{hyperref}
\setmainfont{FiraSans-Regular} % Set Fira Sans as the main font
\setmathfont{STIX Two Math} % Set STIX Two Math for math

\begin{document}
\maketitle

% Node for title, authors, and institute
\node [text=titlefgcolor,
    outer sep=0pt,
    minimum width=\textwidth,
    minimum height=8cm,
    align=center,
    fill=titlebgcolor, inner sep=1mm] at (0,11) {  % Adjust yshift as needed

\begin{minipage}[c][][c]{0.77\linewidth}
    \hspace*{30pt} 
    \fontsize{80}{90}\selectfont \textbf{Multi-person Physics-based Pose Estimation for Combat Sports}\\[12pt]
    \hspace*{30pt} 
    \fontsize{60}{80}\selectfont Hossein Feiz$^{1}$ \quad David Labbé$^{1}$ \quad Sheldon Andrews$^{1}$ \\[6pt]
    \hspace*{30pt} 
    \fontsize{30}{40}\selectfont $^1$École de technologie supérieure, Montréal, Québec, Canada % Adjusted font size
\end{minipage}%
\begin{minipage}[c][][c]{0.23\linewidth}
    \hspace*{-300pt}
    \includegraphics[height=8cm]{figures/image11.png}%
    \hspace*{-10pt} % Adjust spacing between images
    \includegraphics[height=7cm]{figures/image6.png}%
    \hspace*{-10pt} % Adjust spacing between images
    \includegraphics[height=7cm]{figures/image5.png}%
    \hspace*{-10pt} % Adjust spacing between images
    \includegraphics[height=7cm]{figures/image9.png}
\end{minipage}

};

\begin{columns}
\column{0.5}
\block{Introduction}{
    Motion capture from only RGB cameras in a typical sports scene (e.g., boxing), with the presence of coaches, viewers, and close interactions between athletes, brings many challenges, such as heavy occlusion, background crowding, and fast, complicated movements. To address this problematic, a multi-view configuration was used. Our system only required the visibility of an athlete from two cameras. We also created a pipeline using machine and deep learning techniques that automated the process of creating animations~\cite{guo2021multi}.
}

\block{Pipeline}{
\begin{overpic}[scale=3]{figures/pipeline.pdf}
\color{white}
\put(14.6,28.5){\rotatebox{-90}{\fontsize{22}{16}\selectfont Yolov8}}
\put(21.4,28.5){\rotatebox{-90}{\fontsize{22}{16}\selectfont XMem}}
\put(26.6,32.5){\rotatebox{-90}{\fontsize{22}{16}\selectfont Epipolar Constraints}}
\put(32.4,28.5){\rotatebox{-90}{\fontsize{22}{16}\selectfont ViTPose}}
\put(68,31.8){\fontsize{30}{16}\selectfont GMM Prior, VPoser}

\put(68,19.5){\fontsize{40}{16}\selectfont$L_{2D}+L_{3D}+L_{\beta}$}
\color{black}
\put(69.5,26.1){\fontsize{18}{20}\selectfont Kinematics Optimization}
\put(17,5.6){\fontsize{22}{16}\selectfont Physics Body Model Generator}
\put(57,5.6){\fontsize{22}{16}\selectfont Multi-person Dynamics Optimization}
\put(13,35){\fontsize{20}{16}\selectfont Multi-frame Multi-view Tracking IDs}
\put(38.5,35){\fontsize{20}{16}\selectfont Weighted Triangulation and Filtering

}
\put(0,2){\fontsize{7}{16}\selectfont$\mathrm{Y}_1$}
\put(90,19){\includegraphics[scale=0.2]{figures/smpl2.png}} 
\put(0.5,8){\includegraphics[scale=0.13]{figures/smpl-fat.png}} 
\put(0,0){\includegraphics[scale=0.13]{figures/smpl-tall.png}}
\put(43.2,8){\includegraphics[scale=0.13]{figures/mujoco-fat.png}} 
\put(43,0){\includegraphics[scale=0.13]{figures/mujoco-tall.png}} 
\put(88,0){\includegraphics[scale=0.28]{figures/final.png}} 
\end{overpic}}

\block{Multi-frame Multi-view Tracking IDs}{
    \begin{minipage}{\linewidth}
        \begin{itemize}
            \item \textbf{Tracking by Segmentation}: XMem is used for consistent ID assignment across frames by segmenting individuals in each view.
            \item \textbf{Epipolar Constraint-based ID Matching}: IDs are aligned across multiple views by processing bounding box centroids with epipolar constraints.
            \item \textbf{Top-Down 2D Pose Estimation}: This approach involves detecting individuals first and then localizing keypoints within the bounding boxes, ensuring precise and scalable pose estimation, particularly effective in challenging scenarios like low-resolution videos or fast movements.
        \end{itemize}
    \end{minipage}
}

\block{Weighted Triangulation and Filtering}{
    The weighted triangulation estimates the 3D positions of the keypoints from their corresponding 2D keypoints from all $N$ cameras. The 3D positions of each joint are thus determined by solving the linear system:

    \begin{tabular}{@{}p{0.55\textwidth}@{} p{0.4\textwidth}@{}}
        \innerblock[titlewidthscale=0.4, bodywidthscale=0.4]{Weighted Triangulation Formulation}{
        \begin{equation}
        \begin{bmatrix}
        \mu_{1} (\mathbf{P}_{11} - \mathrm{u}_1 \mathbf{P}_{31}) \\
        \mu_{1} (\mathbf{P}_{21} - \mathrm{v}_1 \mathbf{P}_{31}) \\
        \vdots \\
        \mu_{N} (\mathbf{P}_{1N} - \mathrm{u}_N \mathbf{P}_{3N}) \\
        \mu_{N} (\mathbf{P}_{2N} - \mathrm{v}_N \mathbf{P}_{3N}) \\
        \end{bmatrix}
        \begin{bmatrix}
        \mathrm{x} \\
        \mathrm{y} \\
        \mathrm{z} \\
        1
        \end{bmatrix}
        =
        \begin{bmatrix}
        0\\
        \vdots \\
        0
        \end{bmatrix} \,,
        \label{eq:tri}
        \end{equation}
        } &
        \vspace{-260pt}
        \hspace{-1100pt}
        \parbox[t]{0.55\linewidth}{
            $\mathbf{P}_{ij}$ extracts the $i$-th row of the projection matrix $\mathbf{P}_{j}$. $\mu_{j}$ is the average confidence of a 2D point for the current frame in camera $j$. Higher confidence values give more weight to certain cameras.
            \\ We use SVD to solve Eq.~\ref{eq:tri}. After triangulation, outliers are handled by interpolating and smoothing using cubic spline for each joint's trajectory. 
        }
    \end{tabular}
     \vskip -1.4cm
     If there is no solution for triangulation, we utilize an extended Kalman filter for dynamic state estimation based on velocity, acceleration of the keypoint, and position constraint to estimate the 3D keypoints. This results in robust filtering and smoothing while preserving trajectory integrity, enabling dependable 3D reconstructions from sparse and noisy 2D keypoints.
}

\column{0.5}
\block{Kinematics Optimization}{
Our kinematics optimization refines the SMPL model to minimize the difference between the provided 2D poses ($\mathbf{J}_{\text{2D}}$) from multiple views and 3D keypoints ($\mathbf{J}_{\text{3D}}$) obtained from triangulation. The process ensures temporal coherency and natural motion by incorporating smoothness and human motion priors. An LBFGS optimizer is used to solve the minimization problem, considering various loss terms, including 2D re-projection, 3D alignment, smoothness, and prior losses.

\innerblock{Kinematics Optimization Formulation}{
    \begin{align}
      \min_{\theta} \quad & w_1 \, \mathrm{L}_\text{2D} + w_2 \, \mathrm{L}_\text{3D} + w_3 \, \mathrm{L}_\text{reg} +  w_4 \, \mathrm{L}_\text{smooth} + w_5 \, \mathrm{L}_{\text{GMM}} + w_6 \, \mathrm{L}_{\text{Vposer}} \,\,.
    \end{align}
    \begin{multicols}{2}
            \begin{equation}
          \mathrm{L}_\text{2D} = \sum\limits{\text{j} \in \text{$\mathcal{V}$}} \, \sum\limits{\text{i} \in \text{$\mathbf{J}_{2D}$}} c_\text{j,i} \rho (\mathrm{J}_{\text{proj}_{j,i}} - \mathrm{J}_{2D_{j,i}})  \,,
        \end{equation}

        \begin{equation}
          \mathrm{L}_\text{3D} = \sum\limits{\text{i} \in \text{$\mathbf{J}_{3D}$}} c_i \| \mathrm{J}_i(\theta, \beta) - \mathrm{J}_{3D,i}\|^2 \,,
        \end{equation}

        \begin{equation}
          \mathrm{L}_{\text{smooth}} = \sum\limits{t} \| \theta^t - \theta^{t-1} \|^2 + \| \mathcal{M}(\theta^t, \beta) - \mathcal{M}(\theta^{t-1}, \beta) \|^2 \,.
        \end{equation}

        \begin{equation}
        \mathrm{L}_{\text{GMM}} = \frac{1}{N} \sum_{i=1}^{N} \text{GMM}(\theta_i, \beta), \quad \mathrm{L}_{\text{Vposer}} = \frac{1}{N} \sum_{i=1}^{N} (\text{z}(\theta_i)^{2}) \,.
        \end{equation}
    \end{multicols}
}
}

\useblockstyle{blockred}
\block{Physics Body Model Generator}{
    Since our goal is to reconstruct the motion of $K$ physics-based humanoids at each time step $t$, we define the combined state of all humanoids as $\mathbf{x}_t = (\mathbf{q}_t, \mathbf{v}_t)$, where $\mathbf{q}_t \in \mathbb{R}^{63K}$ and $\mathbf{v}_t \in \mathbb{R}^{62K}$ represent the rotation and velocity of the joints. Whereas $\mathbf{q}_t$ is a minimal coordinate representation of position-level coordinates, we also compute $\mathbf{p}_t \in \mathbb{R}^{21K}$ which are the 3D positions of the SMPL joints relative to the humanoid's body frame of reference. This vector is used for the optimization process.
}

\useblockstyle{ets}
\block{Multi-person Dynamics Optimization}{
The iLQR algorithm~\cite{howell2022} optimizes a control trajectory \(\mathbf{u}_{0:T}\) by minimizing the cost function:
\begin{tabular}{@{}p{0.55\textwidth}@{} p{0.43\textwidth}@{}}
\innerblock[titlewidthscale=0.4, bodywidthscale=0.4]{Dynamics Optimization Formulation}{
\begin{equation}
 \min_{\mathbf{u}_{0:T}} \sum_{t=0}^{T} w_1 \mathrm{L_{\text{reg},t}} + w_2 \mathrm{L}_{\text{p},t} + w_3 \mathrm{L}_{\text{v},t} + w_4 \mathrm{L}_{\text{collision},t} \,.
 \label{eq:mpc_opt}
\end{equation}
}&
        \vspace{-180pt}
        \hspace{-1100pt}
        \parbox[t]{0.55\linewidth}{
            The reference positions $\mathbf{p}_{t}$ and velocities $\mathbf{v}_t$ are extracted from the kinematics optimization at each frame $t$, and the trajectory optimization is "warm-started" using control parameters $\mathbf{u}_{t-1}$ from the previous frame.
        }
    \end{tabular}
     \vskip -1.4cm


 

The control is updated iteratively as \(\Delta\mathbf{u}_t = \mathbf{K}_t\Delta\mathbf{x}_t + \alpha \mathbf{k}_t\), with \(\mathbf{K}_t\) and \(\mathbf{k}_t\) refined until convergence.
}

\block[titlewidthscale=0.6, bodywidthscale=0.6, titleoffsetx=-11.5cm, bodyoffsetx=-11.5cm, titleoffsety=0cm, bodyoffsety=0cm]{Discussion and Future Works}{
    We created a 10-hour dataset of boxing motions showcasing various \\ interactions, techniques, and styles. This dataset is being used to \\ develop an interaction motion synthesis model for  generating \\intelligent VR responses.
}

\block[titlewidthscale=0.385, bodywidthscale=0.385, titleoffsetx=17.5cm, bodyoffsetx=17.5cm, titleoffsety=10.7cm, bodyoffsety=10.7cm]{Visualization}{
    \begin{tikzpicture}[inner sep=0pt, outer sep=0pt]
        % First image
        \node (img1) at (0,0) {\includegraphics[width=5.5cm, height=5cm]{figures/image20.png}};
        
        % Second image to the right of the first
        \node (img2) at (2.2,0) {\includegraphics[width=5.5cm, height=5cm]{figures/image21.png}};
        
        % Third image to the right of the second
        \node (img3) at (4.3,0) {\includegraphics[width=5.5cm, height=5cm]{figures/image23.png}};
        
        % Arrows between images
        \draw[->, line width=2mm] (img1.east) -- (img2.west);
        \draw[->, line width=2mm] (img2.east) -- (img3.west);
    \end{tikzpicture}
}

   

\block[titleoffsetx=0cm, bodyoffsetx=0cm, titleoffsety=1cm, bodyoffsety=1cm]{References}{   
        \renewcommand*{\bibfont}{\small} 
        \printbibliography[heading=none]
   
}
\end{columns}

% Node for images at the bottom of the poster
\node [above right,
    text=titlefgcolor,
    outer sep=0pt,
    minimum width=\textwidth,
    minimum height=2cm,
    align=left,
    fill=titlebgcolor, inner sep=1mm] at (bottomleft) {
    \begin{tikzpicture}[scale=0.3]
        \draw (0,0) -- (1,0) -- (1,0.7) -- (0,0.7) -- cycle; % Envelope outline
        \draw (0,0.7) -- (0.5,0.35) -- (1,0.7); % Envelope flap
    \end{tikzpicture}
     \href{mailto:hfa.zadeh.k@gmail.com}{hfa.zadeh.k@gmail.com}
};

\end{document}